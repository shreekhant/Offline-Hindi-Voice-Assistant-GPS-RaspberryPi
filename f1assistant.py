# -*- coding: utf-8 -*-

import json
import sounddevice as sd
import vosk
import subprocess
import numpy as np
from datetime import datetime

# ---------------- CONFIG ----------------
MODEL_PATH = "vosk-model-hi"
SAMPLE_RATE = 44100
DEVICE_ID = 2              # USB mic from your device list
RECORD_SECONDS = 4

# Piper model
PIPER_MODEL = "hi_IN-pratham-medium.onnx"

# ----------------------------------------

# Load Vosk
model = vosk.Model(MODEL_PATH)
rec = vosk.KaldiRecognizer(model, SAMPLE_RATE)

# ---------------- SPEAK FUNCTION ----------------
def speak(text):
    print("TTS TEXT:", text)
    subprocess.run(
        f'echo "{text}" | piper --model {PIPER_MODEL} --output-raw | aplay -D hw:0,0 -r 22050 -f S16_LE -t raw -',
        shell=True
    )

# ---------------- INTENTS ----------------
INTENTS = {
    "date": ["‡§§‡§æ‡§∞‡•Ä‡§ñ", "‡§Ü‡§ú ‡§ï‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§ñ"],
    "time": ["‡§∏‡§Æ‡§Ø", "‡§ï‡§ø‡§§‡§®‡•á ‡§¨‡§ú‡•á"],
    "city": ["‡§∂‡§π‡§∞"],
    "state": ["‡§∞‡§æ‡§ú‡•ç‡§Ø"],
    "add": ["‡§ú‡•ã‡§°‡§º", "‡§™‡•ç‡§≤‡§∏"],
    "multiply": ["‡§ó‡•Å‡§£‡§æ"],
    "divide": ["‡§≠‡§æ‡§ó"],
    "alarm": ["‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ"],
    "joke": ["‡§ú‡•ã‡§ï"],
    "exit": ["‡§¨‡§Ç‡§¶", "‡§Ö‡§≤‡§µ‡§ø‡§¶‡§æ"]
}

# ---------------- INTENT DETECTION ----------------
def detect_intent(text):

    # IMPORTANT: DATE first to avoid overlap
    if any(word in text for word in INTENTS["date"]):
        return "date"

    if any(word in text for word in INTENTS["time"]):
        return "time"

    for intent, words in INTENTS.items():
        if intent in ["date", "time"]:
            continue
        if any(word in text for word in words):
            return intent

    return "unknown"

# ---------------- RESPONSE HANDLER ----------------
def handle_intent(intent):

    if intent == "time":
        return f"‡§Ö‡§≠‡•Ä {datetime.now().strftime('%I:%M')} ‡§¨‡§ú‡•á ‡§π‡•à‡§Ç"

    elif intent == "date":
        return f"‡§Ü‡§ú {datetime.now().strftime('%d/%m/%Y')}"

    elif intent == "city":
        return "‡§Ü‡§™ ‡§ö‡•á‡§®‡•ç‡§®‡§à ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç"

    elif intent == "state":
        return "‡§Ü‡§™ ‡§§‡§Æ‡§ø‡§≤‡§®‡§æ‡§°‡•Å ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§π‡•à‡§Ç"

    elif intent == "add":
        return "20 ‡§ú‡•ã‡§°‡§º 10 ‡§¨‡§∞‡§æ‡§¨‡§∞ 30"

    elif intent == "multiply":
        return "5 ‡§ó‡•Å‡§£‡§æ 6 ‡§¨‡§∞‡§æ‡§¨‡§∞ 30"

    elif intent == "divide":
        return "100 ‡§≠‡§æ‡§ó 4 ‡§¨‡§∞‡§æ‡§¨‡§∞ 25"

    elif intent == "alarm":
        return "‡§∏‡•Å‡§¨‡§π 7 ‡§¨‡§ú‡•á ‡§Ö‡§≤‡§æ‡§∞‡•ç‡§Æ ‡§∏‡•á‡§ü"

    elif intent == "joke":
        return "‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§¨‡•ã‡§≤‡§æ ‡§ï‡§¨ ‡§∏‡•á? ‡§Æ‡§∞‡•Ä‡§ú ‡§¨‡•ã‡§≤‡§æ ‡§ï‡•ç‡§Ø‡§æ?"

    elif intent == "exit":
        return "‡§®‡§Æ‡§∏‡•ç‡§§‡•á"

    else:
        return "‡§∏‡§Æ‡§ù‡§æ ‡§®‡§π‡•Ä‡§Ç"

# ---------------- MAIN LOOP ----------------
print("üî• Stable Offline Assistant Running")

while True:

    print("üé§ Speak...")

    # Record audio
    audio = sd.rec(int(RECORD_SECONDS * SAMPLE_RATE),
                   samplerate=SAMPLE_RATE,
                   channels=1,
                   dtype='int16',
                   device=DEVICE_ID)

    sd.wait()

    data = audio.tobytes()

    if rec.AcceptWaveform(data):

        result = json.loads(rec.Result())
        text = result.get("text", "").strip()

        if text:
            print("üìù:", text)

            intent = detect_intent(text)
            response = handle_intent(intent)

            print("ü§ñ:", response)
            speak(response)

            if intent == "exit":
                break

        else:
            print("No speech detected.")
